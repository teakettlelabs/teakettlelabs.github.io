<!DOCTYPE html>
<html lang="en"><head>
  <title>Teakettle Labs</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image">
<meta name="og:locale" content="en_US">
<meta name="og:site_name" content="Teakettle Labs"><meta name="og:title" content="Ethics and Large Language Models">
<meta name="twitter:title" content="Ethics and Large Language Models"><meta name="og:type" content="article"><meta name="og:image" content="https://www.teakettlelabs.com/assets/images/blog/2022-09-01-ethics-and-llms/teakettle_problem-context_title_iceberg_7.png">
<meta name="twitter:image" content="https://www.teakettlelabs.com/assets/images/blog/2022-09-01-ethics-and-llms/teakettle_problem-context_title_iceberg_7.png"><meta name="og:url" content="https://www.teakettlelabs.com/blog/2022/09/01/ethics-and-llms.html">
<meta name="twitter:url" content="https://www.teakettlelabs.com/blog/2022/09/01/ethics-and-llms.html"><meta name="description" content="As Large Language Models get better and usage spreads, there are some ethical concerns we should think about.">
<meta name="og:description" content="As Large Language Models get better and usage spreads, there are some ethical concerns we should think about.">
<meta name="twitter:description" content="As Large Language Models get better and usage spreads, there are some ethical concerns we should think about.">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/images/rsq_logo_32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/images/rsq_logo_16.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/images/rsq_logo_96.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/assets/images/rsq_logo_192.png">
  <link rel="icon" type="image/png" sizes="400x400" href="/assets/images/rsq_logo_400.png">
  <link rel="alternate" type="application/rss+xml" href="https://www.teakettlelabs.com/blog/feed.xml">
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">
      <img src="/assets/images/logo_w_text_horizontal.png" alt="Teakettle Labs" height="40px">
    </a>

    <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Us</a><a class="page-link" href="/blog/">Blog</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h2 class="post-title p-name" itemprop="name headline">Ethics and Large Language Models</h2>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-09-01T00:00:00-07:00" itemprop="datePublished">Sep 1, 2022
      </time>
      

(4 minute read)

•
          <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">
            Shannon Ladymon
          </span></span>•
          <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">
            Sushanth Sowmyan
          </span></span></p><p>
        <img src="/assets/images/blog/2022-09-01-ethics-and-llms/teakettle_problem-context_title_iceberg_7.png" alt="Ethics and Large Language Models" style="width:100%;margin-left:auto;margin-right:auto" />
      </p></header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In the past decade, we’ve seen huge advancements in machine learning from vanilla neural networks to Large Language Models (LLMs) that seem capable of a surprising level of human-level performance in Natural Language Processing (NLP) tasks. These have led to the establishment of general-purpose foundation models that make advanced NLP accessible - even without a team of specialists - across many markets and domains, leading to widespread adoption.</p>

<p>Enterprise users may interact with sentiment analysis to understand customer opinions, information extraction and summarization to identify key aspects of a document, and transcription to provide records of meetings and improve accessibility. End users may interact with chatbots that answer simple questions, writing assistants that suggest grammar changes, search and personalization that return results individualized to the user, and machine translation that helps communicate across languages.</p>

<p>Such applications make it clear that LLMs are both getting more powerful and more prevalent, but what’s less obvious sometimes is the limitations of these models and the ethical concerns those limitations raise. The sociotechnical complexities of LLMs often end up causing real-world problems that the engineering teams designing LLM applications, despite being deeply technically knowledgeable, are unprepared for.</p>

<figure style="width:80%;margin-left:auto;margin-right:auto">

    
    <img src="/assets/images/blog/2022-09-01-ethics-and-llms/teakettle_problem-context_newsmaking_harms.png" alt="A set of headlines for harms that LLMs have caused, including the Amazon AI recruiting tool, Microsoft's Twitter chatbot Tay, and Facebook's Arabic mistranslation." />
    
    
        <figcaption>LLM applications make headlines when they cause real-world harms</figcaption>
    
    <small>
    
    
    </small>
</figure>

<p>There are quite a few well-publicized examples of how AI models can act in ways that humans find problematic, even when designed for beneficial uses. Amazon, for example, <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">had to abandon an AI recruiting tool</a> they had been working on after discovering that their model learned to discriminate against women. The model had been trained on past resumes submitted to the company, which were heavily skewed towards men. The bias towards men in the data led to bias in the model despite that being completely unintended by its designers.</p>

<p>Another example is when <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">Microsoft had to take down Tay, their Twitter chatbot</a>, after less than a day due to the amount of toxicity it learned from the users it interacted with. Although the bot wasn’t trained to produce such toxicity originally, by allowing unfiltered new data from its online interactions to be fed back into the model, it quickly got out of hand in a way the designers hadn’t anticipated.</p>

<p>There are even some examples of fairly severe real-world consequences, such as when a Palestinian man was arrested by Israeli Police after a <a href="https://www.haaretz.com/israel-news/2017-10-22/ty-article/palestinian-arrested-over-mistranslated-good-morning-facebook-post/0000017f-db61-d856-a37f-ffe181000000">Facebook machine translation model incorrectly translated his post of “good morning”</a> as “attack them” in Hebrew and “hurt them” in English. Even models that have great accuracy will have poor performance in some cases, and when the stakes are high for use cases such as law or health care, this can lead to some extremely worrying outcomes.</p>

<p>These are just a few high-profile examples of the way that LLM applications can cause harm, but there are many more subtle, unexpected, and undesired outcomes as well. In this series of articles, we’ll provide insight into some of the limitations and ethical issues of LLMs and what we can do about it, looking at the following topics:</p>

<h3 id="bias"><a href="/blog/2022/09/15/bias-its-complicated.html">Bias</a></h3>
<p>What exactly is bias? What does it mean for our data and our models?</p>

<h3 id="concrete-harms"><a href="/blog/2022/09/29/concrete-harms-of-llms.html">Concrete Harms</a></h3>
<p>What impact does using LLMs have? What kind of harms can it cause?</p>

<h3 id="fluency-vs-understanding"><a href="/blog/2022/10/13/fluency-vs-understanding.html">Fluency vs Understanding</a></h3>
<p>What is the difference between fluency and understanding? How much do LLMs actually understand, and why does that matter?</p>

<h3 id="bias-in-large-datasets-and-models"><a href="/blog/2022/10/27/bias-in-large-datasets-and-models.html">Bias in Large Datasets and Models</a></h3>
<p>Big data is key to LLMs, but how good is the data we’re training on? How can we work with data that has problems?</p>

<h3 id="good-organizational-practices"><a href="/blog/2022/11/10/org-practices-for-reducing-bias.html">Good Organizational Practices</a></h3>
<p>How should we approach designing and using LLMs? What are some good practices to follow?</p>

<p>We’re hoping that through this discussion we can help LLM application engineers and designers avoid a few of the pitfalls that come with such complex sociotechnical systems and create the best experience possible for users.</p>

<table>
  <tbody>
    <tr>
      <td><a href="/blog/2022/09/15/bias-its-complicated.html">Next : Bias - It’s Complicated &gt;</a></td>
    </tr>
  </tbody>
</table>


  </div>

  <a class="u-url" href="/blog/2022/09/01/ethics-and-llms.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Teakettle Labs</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name"></li><li><a class="u-email" href="mailto:info@teakettlelabs.com">info@teakettlelabs.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3" style="text-align:right;">
        <ul class="related-links" style="list-style:none;">
          <li><a href=/about>About Us</a></li>
          <li><a href=/privacy>Privacy</a></li>
        </ul>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
